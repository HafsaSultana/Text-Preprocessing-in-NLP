{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bag of Words"
      ],
      "metadata": {
        "id": "DWlTHbMRzZmk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e_bbJzmzVDb",
        "outputId": "32804d79-ef0b-43a3-b728-53fabe2b373f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Download NLTK resources if not already downloaded\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample corpus (list of documents)\n",
        "corpus = [\n",
        "    \"I love machine learning\",\n",
        "    \"Machine learning is fun\",\n",
        "    \"I enjoy natural language processing\"\n",
        "]\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the corpus\n",
        "bow_matrix = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Convert the BoW matrix to a dense array (optional for visualization)\n",
        "dense_matrix = bow_matrix.toarray()\n",
        "\n",
        "# Get the feature names (words)\n",
        "feature_names = vectorizer.get_feature_names_out()\n"
      ],
      "metadata": {
        "id": "VWTjSiLhzrXN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the result as a DataFrame for clarity\n",
        "df_bow = pd.DataFrame(dense_matrix, columns=feature_names)\n",
        "\n",
        "print(df_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GrQtCghzuTU",
        "outputId": "f483c5a4-9be2-4ca4-a598-549862f35278"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   enjoy  fun  is  language  learning  love  machine  natural  processing\n",
            "0      0    0   0         0         1     1        1        0           0\n",
            "1      0    1   1         0         1     0        1        0           0\n",
            "2      1    0   0         1         0     0        0        1           1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sGoo0ixw0ACh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}