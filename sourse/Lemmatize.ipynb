{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization using NLTK\n",
        "\n",
        "Converts words to their dictionary form\n",
        "     (e.g., â€œrunningâ€ â†’ â€œrunâ€, â€œbetterâ€ â†’ â€œgoodâ€).\n",
        "\n",
        "Method: Considers context and part of speech.\n",
        "\n",
        "Tool: ð‘Šð‘œð‘Ÿð‘‘ð‘ð‘’ð‘¡ð¿ð‘’ð‘šð‘šð‘Žð‘¡ð‘–ð‘§ð‘’ð‘Ÿ in NLTK, ð‘›ð‘™ð‘.ð‘™ð‘’ð‘šð‘šð‘Žð‘¡ð‘–ð‘§ð‘’ð‘Ÿ in SpaCy.\n",
        "\n",
        "Example: â€œdoneâ€ â†’ â€œdoâ€.\n",
        "\n",
        "Actually, Stemming cuts off word endings, often creating incomplete words, while lemmatization returns proper base forms using dictionaries"
      ],
      "metadata": {
        "id": "eJk76_8_YGOY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "E4dYYvraX_-v"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)  # For additional wordnet support"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4ItSVGlYOCl",
        "outputId": "3a29b50b-ac47-4618-8a9d-b3c8bfafbd94"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Lemmatize the text using WordNetLemmatizer from NLTK.\n",
        "    Parameters: text (str): The text to be lemmatized.\n",
        "    Returns: str: The lemmatized text.\n",
        "    \"\"\"\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Lemmatize each token\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Join the lemmatized tokens back into a single string\n",
        "    return \" \".join(lemmatized_tokens)\n",
        "\n"
      ],
      "metadata": {
        "id": "hoDcG9bfYXQZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    sample_text = \"The cats are running faster than the dogs, but they are better at playing.\"\n",
        "    lemmatized_text = lemmatize_text(sample_text)\n",
        "\n",
        "    print(\"Original Text:\", sample_text)\n",
        "    print(\"Lemmatized Text:\", lemmatized_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo1Re32fYb_5",
        "outputId": "00c97731-f1ef-4d93-af47-5a19294641cb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: The cats are running faster than the dogs, but they are better at playing.\n",
            "Lemmatized Text: The cat are running faster than the dog , but they are better at playing .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OHHyapElYc_8"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}