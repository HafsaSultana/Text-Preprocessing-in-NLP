{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMU2QO7QD9EH4ylflkg/70B"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install gensim\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T-VjsseDxiqD","executionInfo":{"status":"ok","timestamp":1728066246972,"user_tz":-360,"elapsed":4682,"user":{"displayName":"Hafsa Sultana","userId":"10428253150812863647"}},"outputId":"efdd793e-3e5a-43a5-ca9f-f7fcafa9574b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n","Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n","Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"]}]},{"cell_type":"code","source":["# Import necessary libraries\n","from gensim.models import Word2Vec\n","from nltk.tokenize import word_tokenize\n","import nltk\n","\n","# Download NLTK data for tokenization (if not already downloaded)\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DZSvCIN0xqx_","executionInfo":{"status":"ok","timestamp":1728070077728,"user_tz":-360,"elapsed":5,"user":{"displayName":"Hafsa Sultana","userId":"10428253150812863647"}},"outputId":"d95999c2-cd5f-43f7-ebf7-6320209c2afd"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Example corpus (list of sentences)\n","sentences = [\n","    \"I love machine learning and natural language processing.\",\n","    \"Word2Vec is a useful algorithm in NLP.\",\n","    \"We can use Word2Vec to capture semantic meaning of words.\",\n","    \"Deep learning models often rely on word embeddings.\",\n","    \"The king and queen are part of the royal family.\",\n","    \"The man and woman are important to the history of humanity.\",\n","    \"Machine learning and AI are revolutionizing the world.\"\n","]\n","\n"],"metadata":{"id":"QTxL7Pb4xvd2","executionInfo":{"status":"ok","timestamp":1728070174427,"user_tz":-360,"elapsed":411,"user":{"displayName":"Hafsa Sultana","userId":"10428253150812863647"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Step 1: Preprocess the data (tokenize the sentences)\n","tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n","\n","# Step 2: Train the Word2Vec model\n","# We will use size=100 (dimensions for word vectors), window=5 (context window size), and min_count=1 (ignore words with frequency < 1)\n","model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n","\n","# Step 3: Access the vocabulary of the model\n","print(\"Vocabulary:\\n\", model.wv.index_to_key)\n","\n","# Step 4: Finding similar words\n","similar_words = model.wv.most_similar('machine', topn=3)\n","print(\"\\nMost similar words to 'machine':\\n\", similar_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QzzDSaI_x3NQ","executionInfo":{"status":"ok","timestamp":1728070175654,"user_tz":-360,"elapsed":7,"user":{"displayName":"Hafsa Sultana","userId":"10428253150812863647"}},"outputId":"03fe5cd5-4c05-4996-e683-ec2189880a71"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary:\n"," ['.', 'the', 'and', 'of', 'learning', 'are', 'to', 'machine', 'word2vec', 'algorithm', 'use', 'can', 'we', 'nlp', 'in', 'is', 'useful', 'a', 'semantic', 'processing', 'language', 'natural', 'love', 'capture', 'world', 'meaning', 'revolutionizing', 'ai', 'humanity', 'history', 'important', 'woman', 'man', 'family', 'royal', 'part', 'queen', 'king', 'embeddings', 'word', 'on', 'rely', 'often', 'models', 'deep', 'words', 'i']\n","\n","Most similar words to 'machine':\n"," [('processing', 0.31946805119514465), ('king', 0.2044612169265747), ('useful', 0.1748146265745163)]\n"]}]},{"cell_type":"code","source":["# Step 5: Word vector arithmetic (king - man + woman ≈ queen)\n","result = model.wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n","print(\"\\nResult of 'king' - 'man' + 'woman' is closest to:\\n\", result)\n","\n","# Step 6: Save the model for future use\n","model.save(\"word2vec_example.model\")\n","\n","# To load the model later, use:\n","# loaded_model = Word2Vec.load(\"word2vec_example.model\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pMICazRXx-qA","executionInfo":{"status":"ok","timestamp":1728070177068,"user_tz":-360,"elapsed":5,"user":{"displayName":"Hafsa Sultana","userId":"10428253150812863647"}},"outputId":"2d3eba73-e714-4df9-9321-5d9be733db6a"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Result of 'king' - 'man' + 'woman' is closest to:\n"," [('love', 0.18109464645385742)]\n"]}]},{"cell_type":"code","execution_count":18,"metadata":{"id":"NxTr065ZvfxM","executionInfo":{"status":"ok","timestamp":1728070210289,"user_tz":-360,"elapsed":434,"user":{"displayName":"Hafsa Sultana","userId":"10428253150812863647"}}},"outputs":[],"source":["# vector('king') - vector('man') + vector('woman') ≈ vector('queen')\n"]},{"cell_type":"markdown","source":["### For Increasing the corpus size and Using pre-trained Word2Vec models, load a pre-trained model in gensim:\n"],"metadata":{"id":"eJVsFQZUB40b"}},{"cell_type":"code","source":["from gensim.models import KeyedVectors\n","\n","# Load Google's pre-trained Word2Vec model (this requires internet connection and around 1.5GB of space)\n","pretrained_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n","\n","# Perform the same operation (king - man + woman ≈ queen)\n","result = pretrained_model.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n","print(\"\\nResult of 'king' - 'man' + 'woman' is closest to:\\n\", result)\n"],"metadata":{"id":"LKJAhHkTxSFx","executionInfo":{"status":"ok","timestamp":1728070563706,"user_tz":-360,"elapsed":527,"user":{"displayName":"Hafsa Sultana","userId":"10428253150812863647"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dntC4LssBfqx"},"execution_count":null,"outputs":[]}]}