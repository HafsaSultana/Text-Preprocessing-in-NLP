{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization\n",
        "\n",
        "TextTokenizer is a class that encapsulates tokenization logic. It allows users to select a tokenization method (**nltk**, **spacy**, or **regex**) at initialization.\n",
        "\n",
        "**Methods**:\n",
        "1.   tokenize_nltk: Uses NLTK's word_tokenize.\n",
        "2.   tokenize_spacy: Uses spaCy's tokenizer.\n",
        "3.   tokenize_regex: Uses a regex pattern to extract word tokens.\n"
      ],
      "metadata": {
        "id": "1fKzMEC_MPbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "1eX-BDl_MPKT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRrRttc6MB6d",
        "outputId": "dac418ce-b321-48b1-f33a-b98ed31fe41d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Download NLTK resources if not already downloaded\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentance tokenization using NLTK**"
      ],
      "metadata": {
        "id": "hkDpuNnjMlg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Natural Language Processing (NLP) bridges human language and machines. \\\n",
        "        It enables computers to understand text and speech. \\\n",
        "        NLP helps in tasks like sentiment analysis and machine translation. \\\n",
        "        Chatbots and virtual assistants rely heavily on NLP. \\\n",
        "        This technology powers text summarization tools. \\\n",
        "        It also detects spam emails effectively. \\\n",
        "        NLP is improving rapidly with AI advancements. Its applications are transforming industries worldwide.\"\n",
        "\n",
        "sent = nltk.sent_tokenize(text)\n",
        "print(\"NLTK Tokenization:\", sent)\n",
        "\n",
        "print(\"Num of sentance: \", len(sent))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRH85GsqMgY4",
        "outputId": "d318550a-baf1-466c-c314-66763e9c95db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Tokenization: ['Natural Language Processing (NLP) bridges human language and machines.', 'It enables computers to understand text and speech.', 'NLP helps in tasks like sentiment analysis and machine translation.', 'Chatbots and virtual assistants rely heavily on NLP.', 'This technology powers text summarization tools.', 'It also detects spam emails effectively.', 'NLP is improving rapidly with AI advancements.', 'Its applications are transforming industries worldwide.']\n",
            "Num of sentance:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word tokenization using NLTK**"
      ],
      "metadata": {
        "id": "fbAxo-08MvKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Word Tokenization:\", nltk.word_tokenize(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tTSDH_CMg8d",
        "outputId": "9c2bc7b0-d60a-4efb-caf8-9177843c9394"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Tokenization: ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'bridges', 'human', 'language', 'and', 'machines', '.', 'It', 'enables', 'computers', 'to', 'understand', 'text', 'and', 'speech', '.', 'NLP', 'helps', 'in', 'tasks', 'like', 'sentiment', 'analysis', 'and', 'machine', 'translation', '.', 'Chatbots', 'and', 'virtual', 'assistants', 'rely', 'heavily', 'on', 'NLP', '.', 'This', 'technology', 'powers', 'text', 'summarization', 'tools', '.', 'It', 'also', 'detects', 'spam', 'emails', 'effectively', '.', 'NLP', 'is', 'improving', 'rapidly', 'with', 'AI', 'advancements', '.', 'Its', 'applications', 'are', 'transforming', 'industries', 'worldwide', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization using NLTK, SpaCy and Regex**"
      ],
      "metadata": {
        "id": "SapIObLTNf56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tokenization functions\n",
        "def nltk_tokenize(text: str):\n",
        "    \"\"\"Tokenize text using NLTK.\"\"\"\n",
        "    return word_tokenize(text)\n",
        "\n",
        "def spacy_tokenize(text: str):\n",
        "    \"\"\"Tokenize text using spaCy.\"\"\"\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    return [token.text for token in nlp(text)]\n",
        "\n",
        "def regex_tokenize(text: str):\n",
        "    \"\"\"Tokenize text using regex.\"\"\"\n",
        "    return re.findall(r'\\b\\w+\\b', text)\n"
      ],
      "metadata": {
        "id": "zPpvVYenMkoZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Sample text\n",
        "    text = \"Hello, world! Tokenization is an essential step in NLP.\"\n",
        "\n",
        "    print(\"NLTK Tokenization:\", nltk_tokenize(text))\n",
        "    print(\"spaCy Tokenization:\", spacy_tokenize(text))\n",
        "    print(\"Regex Tokenization:\", regex_tokenize(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lGRkz2CNzW0",
        "outputId": "64c24cce-50d6-4df6-87a2-e641b8b439e5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Tokenization: ['Hello', ',', 'world', '!', 'Tokenization', 'is', 'an', 'essential', 'step', 'in', 'NLP', '.']\n",
            "spaCy Tokenization: ['Hello', ',', 'world', '!', 'Tokenization', 'is', 'an', 'essential', 'step', 'in', 'NLP', '.']\n",
            "Regex Tokenization: ['Hello', 'world', 'Tokenization', 'is', 'an', 'essential', 'step', 'in', 'NLP']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F1H3mPvYN2o0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}